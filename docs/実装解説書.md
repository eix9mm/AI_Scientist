# AI Scientist リポジトリ実装解説書

## 概要

AI Scientistは、完全に自動化された科学的発見のための包括的なシステムです。Large Language Models (LLMs)を使用して、研究のアイデア生成から実験実行、論文執筆、査読まで、科学研究の全プロセスを自動化します。

## システム全体のアーキテクチャ

```
AI Scientist システム
├── アイデア生成 (generate_ideas.py)
├── 実験実行 (perform_experiments.py)
├── 論文執筆 (perform_writeup.py)
├── 査読システム (perform_review.py)
└── テンプレートシステム (templates/)
```

## ディレクトリ構造

```
AI_Scientist/
├── ai_scientist/           # コアモジュール
│   ├── generate_ideas.py   # アイデア生成エンジン
│   ├── perform_experiments.py  # 実験実行エンジン
│   ├── perform_writeup.py  # 論文執筆エンジン
│   ├── perform_review.py   # 査読システム
│   ├── llm.py             # LLM統合レイヤー
│   └── fewshot_examples/   # Few-shot学習用サンプル
├── templates/             # 研究テンプレート
│   ├── nanoGPT/          # 言語モデル研究テンプレート
│   ├── 2d_diffusion/     # 拡散モデル研究テンプレート
│   ├── grokking/         # 汎化研究テンプレート
│   └── ...               # コミュニティ提供テンプレート
├── example_papers/        # 生成された論文例
├── review_iclr_bench/     # 査読ベンチマーク
├── launch_scientist.py    # メインエントリーポイント
└── requirements.txt       # 依存関係
```

## コアモジュール詳細解説

### 1. アイデア生成システム (generate_ideas.py)

#### 機能概要
- LLMを使用して革新的な研究アイデアを生成
- 既存のアイデアとの重複を避ける
- 実現可能性と新規性を評価

#### 主要関数

```python
def generate_ideas(base_dir, client, model, max_num_generations, num_reflections):
    """
    研究アイデアを生成する
    
    Args:
        base_dir: ベースディレクトリ
        client: LLMクライアント
        model: 使用するLLMモデル
        max_num_generations: 最大生成数
        num_reflections: 反省回数
    """
```

#### アイデア評価基準
- **興味深さ** (1-10): 研究コミュニティにとっての関心度
- **実現可能性** (1-10): 利用可能なリソースでの実装可能性
- **新規性** (1-10): 既存研究との差別化度

#### プロンプト設計
システムは以下の構造化されたプロンプトを使用：

```
THOUGHT: アイデアの直感と動機
NEW IDEA JSON: {
    "Name": "アイデアの短縮名",
    "Title": "論文タイトル",
    "Experiment": "実装概要",
    "Interestingness": 1-10,
    "Feasibility": 1-10,
    "Novelty": 1-10
}
```

### 2. 実験実行システム (perform_experiments.py)

#### 機能概要
- 生成されたアイデアを実際のコードとして実装
- 複数回の実験実行と結果比較
- エラーハンドリングと自動修正

#### 実験実行フロー

```python
def perform_experiments(idea, folder_name, coder, baseline_results):
    """
    実験を実行して結果を収集
    
    1. 実験計画の策定
    2. コード実装
    3. 実験実行 (最大5回)
    4. 結果分析
    5. 次の実験への反映
    """
```

#### 制約と設定
- **最大実行回数**: 5回 (MAX_RUNS = 5)
- **最大反復回数**: 4回 (MAX_ITERS = 4)  
- **タイムアウト**: 7200秒 (2時間)
- **エラー出力制限**: 1500文字

#### 実験実行コマンド
```bash
python experiment.py --out_dir=run_i
```

### 3. 論文執筆システム (perform_writeup.py)

#### 機能概要
- 実験結果から学術論文を自動生成
- LaTeXフォーマットでの出力
- 参考文献の自動検索と挿入

#### 論文構成セクション
1. **Abstract** - 研究概要
2. **Introduction** - 研究背景と動機
3. **Related Work** - 関連研究
4. **Background** - 理論的背景
5. **Method** - 提案手法
6. **Experimental Setup** - 実験設定
7. **Results** - 実験結果
8. **Conclusion** - 結論

#### 引用システム統合
```python
def get_citation_aider_prompt(cite_client, cite_model, draft, bibtex_entries, num_rounds):
    """
    Semantic Scholar APIを使用して関連論文を検索し、
    適切な引用を論文に挿入する
    """
```

#### エラーチェック機能
論文執筆時に以下をチェック：
- 図表の適切なクローズ
- 重複ヘッダーの検出
- エスケープシンボルの修正
- 環境の正しい終了

### 4. 査読システム (perform_review.py)

#### 機能概要
- 生成された論文の自動査読
- ICLR査読基準に基づく評価
- 改善提案の生成

#### 査読基準
1. **Technical Quality** - 技術的品質
2. **Novelty/Originality** - 新規性・独創性
3. **Significance** - 重要性
4. **Experimental Design** - 実験設計
5. **Clarity** - 明確性
6. **Soundness** - 理論的健全性

### 5. LLM統合レイヤー (llm.py)

#### サポートされるLLMプロバイダー
```python
AVAILABLE_LLMS = {
    "claude-3-5-sonnet-20241022": "anthropic",
    "gpt-4o-2024-05-13": "openai", 
    "gpt-4o-mini": "openai",
    "deepseek-coder-v2-0724": "openrouter",
    "llama3.1-405b": "openrouter",
    "gemini-1.5-pro": "google"
}
```

#### 統一APIインターフェース
```python
def get_response_from_llm(msg, client, model, system_message=""):
    """
    複数のLLMプロバイダーに対する統一インターフェース
    """
```

## テンプレートシステム

### テンプレート構造
各テンプレートには以下が含まれる：
```
template_name/
├── experiment.py          # 実験実行スクリプト
├── plot.py               # 結果可視化スクリプト
├── template.tex          # LaTeX論文テンプレート
├── run_0/                # ベースライン実行結果
└── notes.txt             # テンプレート説明
```

### 提供されるテンプレート

#### 1. NanoGPT テンプレート
- **対象**: 言語モデル研究
- **特徴**: character-level言語モデル
- **研究分野**: スケーリング、アーキテクチャ改善

#### 2. 2D Diffusion テンプレート  
- **対象**: 拡散モデル研究
- **特徴**: 2次元データ生成
- **研究分野**: ノイズスケジューリング、アーキテクチャ

#### 3. Grokking テンプレート
- **対象**: 汎化研究
- **特徴**: 突然の汎化現象
- **研究分野**: 学習動態、汎化メカニズム

### コミュニティテンプレート
- **SEIR** - 感染症モデリング
- **MobileNetV3** - 画像分類
- **Sketch RNN** - スケッチ生成
- **MACE** - 量子化学
- **Earthquake Prediction** - 地震予測
- **TensorF** - テンソル放射野
- **Probes** - 言語モデル調査

## ワークフロー詳細

### 1. 完全自動実行
```bash
python launch_scientist.py \
    --model gpt-4o-2024-05-13 \
    --experiment nanoGPT \
    --num-ideas 5
```

### 2. 段階的実行
```bash
# アイデア生成のみ
python launch_scientist.py --skip-experiments --skip-writeup

# 実験実行のみ  
python launch_scientist.py --skip-idea-generation --skip-writeup

# 論文執筆のみ
python launch_scientist.py --skip-idea-generation --skip-experiments
```

### 3. 実行フロー
1. **初期化**: テンプレート設定とAPI認証
2. **アイデア生成**: LLMによる革新的アイデア生成
3. **新規性チェック**: Semantic Scholar APIによる類似研究検索
4. **実験計画**: 実験手順の詳細計画
5. **実験実行**: コード実装と複数回実行
6. **結果分析**: 実験結果の統計的分析
7. **論文執筆**: 構造化された学術論文生成
8. **査読**: 自動品質評価と改善提案

## 設定とカスタマイズ

### 環境変数
```bash
export OPENAI_API_KEY="your-openai-key"
export ANTHROPIC_API_KEY="your-anthropic-key"
export S2_API_KEY="your-semantic-scholar-key"
```

### パラメータ調整
```python
# launch_scientist.py内の主要パラメータ
NUM_REFLECTIONS = 3        # アイデア改善回数
MAX_ITERS = 4             # 実験反復回数  
MAX_RUNS = 5              # 最大実験実行回数
```

### カスタムテンプレート作成
1. `templates/your_template/`ディレクトリ作成
2. `experiment.py`実装
3. `template.tex`設定
4. `plot.py`可視化実装
5. ベースライン実行 (`run_0/`)

## 技術的詳細

### 依存関係
- **LLM APIs**: anthropic, openai, google-generativeai
- **コード生成**: aider-chat
- **科学計算**: torch, numpy, transformers
- **可視化**: matplotlib
- **PDF処理**: pypdf, pymupdf4llm
- **その他**: datasets, tiktoken, wandb, tqdm

### エラーハンドリング
- タイムアウト処理
- API制限対応
- 自動リトライ機能
- エラーログ記録

### セキュリティ考慮事項
⚠️ **注意**: このシステムはLLMが生成したコードを実行します
- コンテナ化推奨
- ネットワークアクセス制限
- 危険なパッケージの監視
- 実行権限の制限

## パフォーマンス最適化

### 並列実行
```python
# multiprocessing を使用した並列アイデア生成
num_processes = min(multiprocessing.cpu_count(), max_num_generations)
```

### メモリ管理
- 大量のモデルウェイトの効率的処理
- GPU メモリの最適化
- 中間結果のクリーンアップ

### API使用量最適化
- 適切なモデル選択
- プロンプト長の最適化
- レート制限の遵守

## デバッグとトラブルシューティング

### 一般的な問題
1. **API認証エラー**: 環境変数設定確認
2. **依存関係エラー**: requirements.txt確認
3. **タイムアウトエラー**: 実験の複雑さ調整
4. **メモリエラー**: バッチサイズ削減

### ログ確認
```bash
# 実験実行ログ
cat run_i/experiment.log

# システムログ  
cat ai_scientist.log
```

### デバッグモード
```python
# launch_scientist.py で詳細ログ有効化
import logging
logging.basicConfig(level=logging.DEBUG)
```

## 拡張性と将来の改善

### 拡張可能な要素
1. **新しいLLMプロバイダー**の追加
2. **カスタム査読基準**の実装
3. **新しい研究分野テンプレート**
4. **高度な実験設計**機能

### コミュニティ貢献
- 新しいテンプレートの提供
- バグ報告と修正
- ドキュメント改善
- 性能向上の提案

## 結論

AI Scientistは、科学研究の自動化において画期的なシステムを提供します。LLMの能力を活用して、アイデア生成から論文発表まで、研究プロセス全体を自動化することで、研究者の生産性向上と新しい発見の加速を実現します。

本システムの継続的な改善と拡張により、様々な研究分野での自動化された科学的発見が可能になることが期待されます。